{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1\n",
      "**********************************************\n",
      "\n",
      "         1   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 8090\n",
      "Number Training Cases: 5752\n",
      "Number Validation Cases: 763\n",
      "Number whole Testing Cases: 1575\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 38.98412698412698\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 102517\n",
      "Number Training Cases: 71628\n",
      "Number Validation Cases: 10331\n",
      "Number whole Testing Cases: 20558\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 52.12569316081331\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10538\n",
      "Number Validation Cases: 1466\n",
      "Number whole Testing Cases: 2986\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 83.15472203616878\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         1  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 9501\n",
      "Number Training Cases: 5752\n",
      "Number Validation Cases: 763\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 2.866356144750985Precision: 0.0008215997548551732Recall: 0.028663561447509853F1: 0.0015974119928950108\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 84945\n",
      "Number Training Cases: 71628\n",
      "Number Validation Cases: 10331\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.57697360563717Precision: 0.2870492100739142Recall: 0.5357697360563717F1: 0.37381803187633306\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10538\n",
      "Number Validation Cases: 1466\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.57697360563717Precision: 0.2870492100739142Recall: 0.5357697360563717F1: 0.37381803187633306\n",
      "\n",
      "RUN 2\n",
      "**********************************************\n",
      "\n",
      "         2   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 8090\n",
      "Number Training Cases: 5663\n",
      "Number Validation Cases: 847\n",
      "Number whole Testing Cases: 1580\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 38.607594936708864\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 102517\n",
      "Number Training Cases: 71732\n",
      "Number Validation Cases: 10185\n",
      "Number whole Testing Cases: 20600\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 52.33980582524271\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10523\n",
      "Number Validation Cases: 1528\n",
      "Number whole Testing Cases: 2939\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 83.63388907791766\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         2  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 9449\n",
      "Number Training Cases: 5663\n",
      "Number Validation Cases: 847\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 2.826545642740555Precision: 0.0007989360270495617Recall: 0.02826545642740555F1: 0.001553948976999337\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 84856\n",
      "Number Training Cases: 71732\n",
      "Number Validation Cases: 10185\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.69242406146741Precision: 0.49093879642306143Recall: 0.5369242406146741F1: 0.37734378851126305\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10523\n",
      "Number Validation Cases: 1528\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.51327680242047Precision: 0.28636707941324735Recall: 0.5351327680242047F1: 0.373084446346379\n",
      "\n",
      "RUN 3\n",
      "**********************************************\n",
      "\n",
      "         3   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 8090\n",
      "Number Training Cases: 5609\n",
      "Number Validation Cases: 842\n",
      "Number whole Testing Cases: 1639\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 36.66870042708969\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 102517\n",
      "Number Training Cases: 71759\n",
      "Number Validation Cases: 10241\n",
      "Number whole Testing Cases: 20517\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 90.48106448311157\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10550\n",
      "Number Validation Cases: 1477\n",
      "Number whole Testing Cases: 2963\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 82.8889638879514\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         3  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 9414\n",
      "Number Training Cases: 5609\n",
      "Number Validation Cases: 842\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 2.822564592539512Precision: 0.0007966870879057742Recall: 0.02822564592539512F1: 0.0015496347344823554\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 84963\n",
      "Number Training Cases: 71759\n",
      "Number Validation Cases: 10241\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 84.8202555834229Precision: 0.7358242916068362Recall: 0.8482025558342291F1: 0.7866751867706442\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10550\n",
      "Number Validation Cases: 1477\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.72029141287472Precision: 0.2885869709484181Recall: 0.5372029141287472F1: 0.3754702366173732\n",
      "\n",
      "RUN 4\n",
      "**********************************************\n",
      "\n",
      "         4   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 8090\n",
      "Number Training Cases: 5637\n",
      "Number Validation Cases: 807\n",
      "Number whole Testing Cases: 1646\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 38.03159173754557\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 102517\n",
      "Number Training Cases: 71764\n",
      "Number Validation Cases: 10248\n",
      "Number whole Testing Cases: 20505\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 52.24091684954889\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10517\n",
      "Number Validation Cases: 1505\n",
      "Number whole Testing Cases: 2968\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 83.42318059299191\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         4  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 9412\n",
      "Number Training Cases: 5637\n",
      "Number Validation Cases: 807\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 2.945977148771846Precision: 0.0008702686986391881Recall: 0.02945977148771846F1: 0.00169059564954724\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 84980\n",
      "Number Training Cases: 71764\n",
      "Number Validation Cases: 10248\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.5889167562403Precision: 0.5842019981669233Recall: 0.535889167562403F1: 0.3752786730716115\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10517\n",
      "Number Validation Cases: 1505\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.469485250209004Precision: 0.28589858529223183Recall: 0.53469485250209F1: 0.37258036648277937\n",
      "\n",
      "RUN 5\n",
      "**********************************************\n",
      "\n",
      "         5   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 8090\n",
      "Number Training Cases: 5685\n",
      "Number Validation Cases: 789\n",
      "Number whole Testing Cases: 1616\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 38.056930693069305\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 102517\n",
      "Number Training Cases: 71749\n",
      "Number Validation Cases: 10228\n",
      "Number whole Testing Cases: 20540\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 54.595910418695226\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10484\n",
      "Number Validation Cases: 1543\n",
      "Number whole Testing Cases: 2963\n",
      "\n",
      "\n",
      "Training finished with epsilon: 5\n",
      "\n",
      "Accuracy: 83.46270671616605\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         5  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 9437\n",
      "Number Training Cases: 5685\n",
      "Number Validation Cases: 789\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 2.834507743142641Precision: 0.0008034754013526397Recall: 0.02834507743142641F1: 0.0015626554495683782\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 84940\n",
      "Number Training Cases: 71749\n",
      "Number Validation Cases: 10228\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 55.503801902941994Precision: 0.6089348599037377Recall: 0.55503801902942F1: 0.4144821668841386\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: nsl_kdd\n",
      "Subset: udp\n",
      "Total number of instances: 14990\n",
      "Number Training Cases: 10484\n",
      "Number Validation Cases: 1543\n",
      "Number whole Testing Cases: 25119\n",
      "\n",
      "numTrees: 31\n",
      "\n",
      "Accuracy: 53.65261355945699Precision: 0.28786029417604275Recall: 0.5365261355945699F1: 0.3746897465751901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import DPForest as DPRF\n",
    "import os.path\n",
    "import os\n",
    "from datetime import datetime\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os = \"mac\" #win mac\n",
    "\n",
    "separator = \"\\\\\"\n",
    "\n",
    "if my_os == \"mac\":\n",
    "    separator = \"//\"\n",
    "\n",
    "today = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "dataset = \"nsl_kdd\" # iris kdd  nsl_kdd  unsw_nb15 cic_ids_2017\n",
    "problem = \"AC\" # AD AC\n",
    "TrainingPercentage = 0.7\n",
    "ValidationPercentage = 0.1\n",
    "TestingPercentage = 0.2\n",
    "division = \"subsets\"\n",
    "\n",
    "#0.1, 0.5, 1, 5\n",
    "epsilon = 5\n",
    "\n",
    "no_runs = 5\n",
    "\n",
    "folderName =  'Experiments 2 Subsets DP ' + str(epsilon)   + ' ' + today.strftime(\"%d-%b-%Y %H_%M_%S\")\n",
    "\n",
    "if not os.path.exists(folderName):\n",
    "    os.makedirs(folderName)\n",
    "\n",
    "results_2_1 = []\n",
    "results_2_2 = []\n",
    "results_2_3 = []\n",
    "results_2_4 = []\n",
    "\n",
    "k = 1\n",
    "while k<=no_runs:\n",
    "    # Dividing the dataset\n",
    "    print(\"RUN \" + str(k))\n",
    "\n",
    "    if dataset == \"iris\":\n",
    "        iris = load_iris()\n",
    "        data, target = iris.data, iris.target\n",
    "\n",
    "    if dataset == \"kdd\":\n",
    "        file_name = \"data\" + separator +\"kdd_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 3\n",
    "\n",
    "\n",
    "    if dataset == \"nsl_kdd\":\n",
    "        file_name = \"data\" + separator +\"nsl_kdd_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 4\n",
    "\n",
    "    if dataset == \"unsw_nb15\":\n",
    "        file_name = \"data\" + separator + \"unsw_nb15_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 4\n",
    "\n",
    "    if dataset == \"cic_ids_2017\":\n",
    "        file_name = \"data\" + separator +\"cic_ids_2017_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 0\n",
    "\n",
    "    if problem == \"AD\" and dataset != \"iris\":\n",
    "        target[target != label_for_normal] = 1\n",
    "        target[target == label_for_normal] = 0\n",
    "\n",
    "    num_classes = np.unique(target).shape[0]\n",
    "\n",
    "    classes = np.unique(target)\n",
    "\n",
    "    uniqueSubsets = np.unique(subsets)\n",
    "\n",
    "    total_number_instances = len(data)\n",
    "    indexes = range(len(data))\n",
    "    indexes = random.sample(indexes, round(TrainingPercentage * total_number_instances))\n",
    "    dataTraining = data[indexes,:]\n",
    "    targetTraining = target[indexes]\n",
    "\n",
    "    subsetsTraining = subsets[indexes]\n",
    "    data = np.delete(data, indexes, axis = 0)\n",
    "    target = np.delete(target, indexes, axis = 0)\n",
    "    subsets = np.delete(subsets, indexes, axis = 0)\n",
    "    indexes = range(len(data))\n",
    "    indexes = random.sample(indexes, round(ValidationPercentage * total_number_instances))\n",
    "    dataValidation = data[indexes,:]\n",
    "    targetValidation = target[indexes]\n",
    "    subsetsValidation = subsets[indexes]\n",
    "    dataTesting = np.delete(data, indexes, axis = 0)\n",
    "    targetTesting = np.delete(target, indexes, axis = 0)\n",
    "    subsetsTesting = np.delete(subsets, indexes, axis = 0)\n",
    "\n",
    "    algorithms = []\n",
    "\n",
    "    percentage = 0.7\n",
    "    if dataset == \"kdd\" and problem == \"AD\" :\n",
    "        num_trees = 65\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"kdd\" and problem == \"AC\" :\n",
    "        num_trees = 53\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "\n",
    "    if dataset == \"nsl_kdd\" and problem == \"AD\" :\n",
    "        num_trees = 65\n",
    "        criterion_input = 'gini' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"nsl_kdd\" and problem == \"AC\" :\n",
    "        num_trees = 31\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"unsw_nb15\" and problem == \"AD\" :\n",
    "        num_trees = 93\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "\n",
    "    if dataset == \"unsw_nb15\" and problem == \"AC\" :\n",
    "        num_trees = 61\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"cic_ids_2017\" and problem == \"AD\" :\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "        num_trees = 77\n",
    "\n",
    "    if dataset == \"cic_ids_2017\" and problem == \"AC\" :\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "        num_trees = 95\n",
    "\n",
    "    ok = 1\n",
    "\n",
    "    for i in range(len(uniqueSubsets)):\n",
    "        temp_result = \"\"\n",
    "        ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "        subsetDataTraining = dataTraining[ind_list]\n",
    "        subsetTargetTraining = targetTraining[ind_list]\n",
    "        ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "        subsetDataValidation = dataValidation[ind_list]\n",
    "        subsetTargetValidation = targetValidation[ind_list]\n",
    "        ind_list = np.where(subsetsTesting == uniqueSubsets[i])\n",
    "        subsetDataTesting = dataTesting[ind_list]\n",
    "        subsetTargetTesting = targetTesting[ind_list]\n",
    "        # \n",
    "        # print(np.unique(subsetTargetTraining))\n",
    "        # print(np.unique(subsetTargetValidation))\n",
    "        # print(np.unique(subsetTargetTesting))\n",
    "\n",
    "        if subsetDataTraining.shape[0] == 0 or subsetDataValidation.shape[0]==0 or subsetDataTesting.shape[0] == 0:\n",
    "            print(\"not ok \" + uniqueSubsets[i] + \", again\")\n",
    "            ok = 0\n",
    "\n",
    "    if ok == 0:\n",
    "        continue\n",
    "\n",
    "    f = bz2.BZ2File(folderName+separator+dataset+\"_\"+problem+\"_\"+str(k)+ \"_subsets_for_Experiment3.pbz2\", \"wb\")\n",
    "    cPickle.dump((dataTraining,targetTraining,subsetsTraining,dataValidation,targetValidation,subsetsValidation,dataTesting,targetTesting,subsetsTesting),f)\n",
    "    f.close()\n",
    "\n",
    "    result = \"\"\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    print(\"         \" + str(k)  + \"   EXPERIMENT 2.1\")\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    one_run_2_1 = []\n",
    "    if division == \"subsets\":\n",
    "        result = result + \"2.1\\n\\n\\n\"\n",
    "\n",
    "        for i in range(len(uniqueSubsets)):\n",
    "            temp_result = \"\"\n",
    "            ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "            subsetDataTraining = dataTraining[ind_list]\n",
    "            subsetTargetTraining = targetTraining[ind_list]\n",
    "            ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "            subsetDataValidation = dataValidation[ind_list]\n",
    "            subsetTargetValidation = targetValidation[ind_list]\n",
    "            ind_list = np.where(subsetsTesting == uniqueSubsets[i])\n",
    "            subsetDataTesting = dataTesting[ind_list]\n",
    "            subsetTargetTesting = targetTesting[ind_list]\n",
    "\n",
    "            total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+str(uniqueSubsets[i])+\"\\n\"\n",
    "            temp_result = temp_result + \"Total number of instances: \"+str(total_number_instances_subset)+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number whole Testing Cases: \"+str(subsetDataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "            print(temp_result)\n",
    "\n",
    "            temp_result = temp_result + \"numTrees: \"+str(num_trees)+\"\\n\"\n",
    "            algorithms.append(DPRF.DPRandomForest(num_trees, criterion_input, ensemble_method, classes=classes, epsilon=epsilon, shuffle=True))\n",
    "            # algorithms.append(RF.RandomForest(num_trees, criterion_input, ensemble_method, num_classes))\n",
    "            algorithms[-1].fit(subsetDataTraining, subsetTargetTraining, percentage)\n",
    "            algorithms[-1].validate(subsetDataValidation, subsetTargetValidation)\n",
    "            algorithms[-1].predict(subsetDataTesting, subsetTargetTesting)\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[-1].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[-1].statisticsRF.precision) + \"Recall: \" + str(algorithms[-1].statisticsRF.recall) + \"F1: \" + str(algorithms[-1].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_1.append(algorithms[-1].statisticsRF)\n",
    "            print(\"\\nAccuracy: \" + str(algorithms[-1].statisticsRF.accuracy)+\"\\n\")\n",
    "            result = result + temp_result\n",
    "        results_2_1.append(one_run_2_1)\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    print(\"         \" + str(k)  + \"  EXPERIMENT 2.2\")\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "\n",
    "    if division == \"subsets\":\n",
    "        result = result + \"\\n\\n\\n2.2\\n\\n\\n\"\n",
    "        one_run_2_2 = []\n",
    "        for i in range(len(uniqueSubsets)):\n",
    "            temp_result = \"\"\n",
    "\n",
    "            ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "            subsetDataTraining = dataTraining[ind_list]\n",
    "            subsetTargetTraining = targetTraining[ind_list]\n",
    "            ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "            subsetDataValidation = dataValidation[ind_list]\n",
    "            subsetTargetValidation = targetValidation[ind_list]\n",
    "\n",
    "            total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+str(uniqueSubsets[i])+\"\\n\"\n",
    "            temp_result = temp_result + \"Total number of instances: \"+str(total_number_instances_subset)+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number whole Testing Cases: \"+str(dataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"numTrees: \"+str(num_trees)+\"\\n\"\n",
    "\n",
    "            algorithms[i].predict(dataTesting, targetTesting)\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[i].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[i].statisticsRF.precision) + \"Recall: \" + str(algorithms[i].statisticsRF.recall) + \"F1: \" + str(algorithms[i].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_2.append(algorithms[i].statisticsRF)\n",
    "            print(temp_result)\n",
    "            result = result + temp_result\n",
    "        results_2_2.append(one_run_2_2)\n",
    "\n",
    "    #f = open(folderName+\"\\\\\"+\"Experiment_2_2_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method, \"wb\")\n",
    "    # f = bz2.BZ2File(folderName+separator+\"Experiment_2_2_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method+ \"_\" + str(k) + \".pbz2\", \"wb\")\n",
    "    # cPickle.dump((algorithms),f)\n",
    "    # f.close()\n",
    "\n",
    "    # print(\"Results 2.1\")\n",
    "    # print(results_2_1)\n",
    "    # print(\"Results 2.2\")\n",
    "    # print(results_2_2)\n",
    "\n",
    "\n",
    "    f = bz2.BZ2File(folderName+separator+\"Experiment_2_2_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method+ \"_\" + str(k) + \".pbz2\", \"wb\")\n",
    "    cPickle.dump((algorithms),f)\n",
    "    f.close()\n",
    "\n",
    "    f1 = open(folderName+separator+\"output_\"+dataset+\"_\"+problem+\".txt\", \"w\")\n",
    "    f1.write(result)\n",
    "    f1.close()\n",
    "\n",
    "    k = k + 1\n",
    "\n",
    "\n",
    "if division == \"subsets\":\n",
    "    avg_2_1 = []\n",
    "    avg_2_2 = []\n",
    "\n",
    "    prec_2_1 = []\n",
    "    prec_2_2 = []\n",
    "\n",
    "    recall_2_1 = []\n",
    "    recall_2_2 = []\n",
    "\n",
    "\n",
    "    f1_2_1 = []\n",
    "    f1_2_2 = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum2a = 0\n",
    "        sum1p = 0\n",
    "        sum2p = 0\n",
    "        sum1r = 0\n",
    "        sum2r = 0\n",
    "        sum1f = 0\n",
    "        sum2f = 0\n",
    "        for z in range(len(results_2_1)):\n",
    "           sum1a = sum1a + results_2_1[z][k].accuracy\n",
    "           sum2a = sum2a + results_2_2[z][k].accuracy\n",
    "           sum1p = sum1p + results_2_1[z][k].precision\n",
    "           sum2p = sum2p + results_2_2[z][k].precision\n",
    "           sum1r = sum1r + results_2_1[z][k].recall\n",
    "           sum2r = sum2r + results_2_2[z][k].recall\n",
    "           sum1f = sum1f + results_2_1[z][k].f1\n",
    "           sum2f = sum2f + results_2_2[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        avg_temp2 = sum2a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        prec_temp2 = sum2p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        r_temp2 = sum2r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        f1_temp2 = sum2f/no_runs\n",
    "        avg_2_1.append(avg_temp1)\n",
    "        avg_2_2.append(avg_temp2)\n",
    "        prec_2_1.append(prec_temp1)\n",
    "        prec_2_2.append(prec_temp2)\n",
    "        recall_2_1.append(r_temp1)\n",
    "        recall_2_2.append(r_temp2)\n",
    "        f1_2_1.append(f1_temp1)\n",
    "        f1_2_2.append(f1_temp2)\n",
    "\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_1.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/accuracy\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/precision\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/recall\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_1)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_1[k][j].accuracy)\n",
    "            oneRow.append(results_2_1[k][j].precision*100)\n",
    "            oneRow.append(results_2_1[k][j].recall*100)\n",
    "            oneRow.append(results_2_1[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_1[j])\n",
    "        lastRow.append(prec_2_1[j]*100)\n",
    "        lastRow.append(recall_2_1[j]*100)\n",
    "        lastRow.append(f1_2_1[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_2.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(firstRow)\n",
    "    for k in range(len(results_2_2)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_2[k][j].accuracy)\n",
    "            oneRow.append(results_2_2[k][j].precision*100)\n",
    "            oneRow.append(results_2_2[k][j].recall*100)\n",
    "            oneRow.append(results_2_2[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_2[j])\n",
    "        lastRow.append(prec_2_2[j]*100)\n",
    "        lastRow.append(recall_2_2[j]*100)\n",
    "        lastRow.append(f1_2_2[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if division == \"random_equal\":\n",
    "    avg_2_3 = []\n",
    "    prec_2_3 = []\n",
    "    recall_2_3 = []\n",
    "    f1_2_3 = []\n",
    "\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum1p = 0\n",
    "        sum1r = 0\n",
    "        sum1f = 0\n",
    "        for z in range(len(results_2_3)):\n",
    "            sum1a = sum1a + results_2_3[z][k].accuracy\n",
    "            sum1p = sum1p + results_2_3[z][k].precision\n",
    "            sum1r = sum1r + results_2_3[z][k].recall\n",
    "            sum1f = sum1f + results_2_3[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        avg_2_3.append(avg_temp1)\n",
    "        prec_2_3.append(prec_temp1)\n",
    "        recall_2_3.append(r_temp1)\n",
    "        f1_2_3.append(f1_temp1)\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_3.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/accuracy\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/precision\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/recall\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_3)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_3[k][j].accuracy)\n",
    "            oneRow.append(results_2_3[k][j].precision*100)\n",
    "            oneRow.append(results_2_3[k][j].recall*100)\n",
    "            oneRow.append(results_2_3[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_3[j])\n",
    "        lastRow.append(prec_2_3[j]*100)\n",
    "        lastRow.append(recall_2_3[j]*100)\n",
    "        lastRow.append(f1_2_3[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "if division == \"random_same\":\n",
    "    avg_2_4 = []\n",
    "    prec_2_4 = []\n",
    "    recall_2_4 = []\n",
    "    f1_2_4 = []\n",
    "\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum1p = 0\n",
    "        sum1r = 0\n",
    "        sum1f = 0\n",
    "        for z in range(len(results_2_4)):\n",
    "            sum1a = sum1a + results_2_4[z][k].accuracy\n",
    "            sum1p = sum1p + results_2_4[z][k].precision\n",
    "            sum1r = sum1r + results_2_4[z][k].recall\n",
    "            sum1f = sum1f + results_2_4[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        avg_2_4.append(avg_temp1)\n",
    "        prec_2_4.append(prec_temp1)\n",
    "        recall_2_4.append(r_temp1)\n",
    "        f1_2_4.append(f1_temp1)\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_4.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(k+1) + \"/accuracy\")\n",
    "        firstRow.append(str(k+1) + \"/precision\")\n",
    "        firstRow.append(str(k+1) + \"/recall\")\n",
    "        firstRow.append(str(k+1) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_4)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_4[k][j].accuracy)\n",
    "            oneRow.append(results_2_4[k][j].precision*100)\n",
    "            oneRow.append(results_2_4[k][j].recall*100)\n",
    "            oneRow.append(results_2_4[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_4[j])\n",
    "        lastRow.append(prec_2_4[j]*100)\n",
    "        lastRow.append(recall_2_4[j]*100)\n",
    "        lastRow.append(f1_2_4[j]*100)\n",
    "\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}