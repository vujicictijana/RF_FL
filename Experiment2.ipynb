{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1\n",
      "**********************************************\n",
      "\n",
      "         1   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 283235\n",
      "Number Training Cases: 198478\n",
      "Number Validation Cases: 28132\n",
      "Number whole Testing Cases: 56625\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.98763796909492\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 189786\n",
      "Number Training Cases: 132679\n",
      "Number Validation Cases: 19144\n",
      "Number whole Testing Cases: 37963\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.87092695519321\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: udp\n",
      "Total number of instances: 20326\n",
      "Number Training Cases: 14186\n",
      "Number Validation Cases: 2059\n",
      "Number whole Testing Cases: 4081\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.75496201911295\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         1  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 230691\n",
      "Number Training Cases: 198478\n",
      "Number Validation Cases: 28132\n",
      "Number whole Testing Cases: 98669\n",
      "\n",
      "numTrees: 53\n",
      "\n",
      "Accuracy: 74.11851746749232Precision: 0.6543759327491262Recall: 0.7411851746749232F1: 0.6827943083016998\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 155904\n",
      "Number Training Cases: 132679\n",
      "Number Validation Cases: 19144\n",
      "Number whole Testing Cases: 98669\n",
      "\n",
      "numTrees: 53\n",
      "\n",
      "Accuracy: 42.408456556770616Precision: 0.2772017595369023Recall: 0.4240845655677062F1: 0.3073536235962956\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: udp\n",
      "Total number of instances: 20326\n",
      "Number Training Cases: 14186\n",
      "Number Validation Cases: 2059\n",
      "Number whole Testing Cases: 98669\n",
      "\n",
      "numTrees: 53\n",
      "\n",
      "Accuracy: 20.10053816294885Precision: 0.04216688080295828Recall: 0.2010053816294885F1: 0.06850646608027201\n",
      "\n",
      "Results 2.1\n",
      "[[<RandomForest.Statistics object at 0x7feb664956a0>, <RandomForest.Statistics object at 0x7feb36111550>, <RandomForest.Statistics object at 0x7feb36110460>]]\n",
      "Results 2.2\n",
      "[[<RandomForest.Statistics object at 0x7feb66495fa0>, <RandomForest.Statistics object at 0x7feb36111eb0>, <RandomForest.Statistics object at 0x7feb36110dc0>]]\n",
      "**********************************************\n",
      "\n",
      "            EXPERIMENT 2.3\n",
      "\n",
      "**********************************************\n",
      "RUN 2\n",
      "**********************************************\n",
      "\n",
      "         2   EXPERIMENT 2.1\n",
      "\n",
      "**********************************************\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: icmp\n",
      "Total number of instances: 283235\n",
      "Number Training Cases: 198383\n",
      "Number Validation Cases: 28223\n",
      "Number whole Testing Cases: 56629\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.98940472196225\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: tcp\n",
      "Total number of instances: 189786\n",
      "Number Training Cases: 132732\n",
      "Number Validation Cases: 19054\n",
      "Number whole Testing Cases: 38000\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.82631578947368\n",
      "\n",
      "\n",
      " INFORMATION\n",
      "\n",
      "Dataset: kdd\n",
      "Subset: udp\n",
      "Total number of instances: 20326\n",
      "Number Training Cases: 14228\n",
      "Number Validation Cases: 2058\n",
      "Number whole Testing Cases: 4040\n",
      "\n",
      "\n",
      "Training finished\n",
      "\n",
      "Accuracy: 99.75247524752476\n",
      "\n",
      "**********************************************\n",
      "\n",
      "         2  EXPERIMENT 2.2\n",
      "\n",
      "**********************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/sy/n7rh139x6tl49pn2wm46j4vd7tmz20/T/ipykernel_21375/4192946438.py\", line 257, in <module>\n",
      "    algorithms[i].predict(dataTesting, targetTesting)\n",
      "  File \"/Users/tmc01/DataspellProjects/paper3/for git/RandomForest.py\", line 125, in predict\n",
      "    results[j,self.statisticsTrees[i].prediction[j]] += self.statisticsTreesValidation[i].accuracyClass[self.statisticsTrees[i].prediction[j]] * np.average(self.statisticsTreesValidation[i].accuracyClass)\n",
      "  File \"<__array_function__ internals>\", line 200, in average\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\", line 518, in average\n",
      "    avg = a.mean(axis, **keepdims_kw)\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\", line 181, in _mean\n",
      "    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/posixpath.py\", line 392, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/posixpath.py\", line 426, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/tmc01/opt/anaconda3/lib/python3.9/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m/var/folders/sy/n7rh139x6tl49pn2wm46j4vd7tmz20/T/ipykernel_21375/4192946438.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m             \u001B[0malgorithms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataTesting\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargetTesting\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m             \u001B[0mtemp_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtemp_result\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"\\nAccuracy: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsRF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m \u001B[0;34m\"Precision: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsRF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprecision\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"Recall: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsRF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecall\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"F1: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsRF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/paper3/for git/RandomForest.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, Data, target)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m                     \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsTrees\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprediction\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsTreesValidation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracyClass\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsTrees\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprediction\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maverage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatisticsTreesValidation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracyClass\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001B[0m in \u001B[0;36maverage\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001B[0m in \u001B[0;36maverage\u001B[0;34m(a, axis, weights, returned, keepdims)\u001B[0m\n\u001B[1;32m    517\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mweights\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 518\u001B[0;31m         \u001B[0mavg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkeepdims_kw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    519\u001B[0m         \u001B[0mavg_as_array\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masanyarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mavg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001B[0m in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 181\u001B[0;31m     \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mumr_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    182\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mret\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2063\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2064\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2065\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2064\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2065\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2066\u001B[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[1;32m   2067\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[1;32m   2068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import RandomForest as RF\n",
    "import os.path\n",
    "import os\n",
    "from datetime import datetime\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os = \"mac\" #win mac\n",
    "\n",
    "separator = \"\\\\\"\n",
    "\n",
    "if my_os == \"mac\":\n",
    "    separator = \"//\"\n",
    "\n",
    "division = \"subsets\" # subsets random_equal random_same\n",
    "\n",
    "today = datetime.now()\n",
    "\n",
    "if division == \"subsets\":\n",
    "    folderName =  'Experiments 2 '  + today.strftime(\"%d-%b-%Y %H_%M_%S\")\n",
    "else:\n",
    "    folderName =  'Experiments 2 ' + division + ' '  + today.strftime(\"%d-%b-%Y %H_%M_%S\")\n",
    "\n",
    "if not os.path.exists(folderName):\n",
    "    os.makedirs(folderName)\n",
    "\n",
    "dataset = \"kdd\" # iris kdd  nsl_kdd  unsw_nb15 cic_ids_2017\n",
    "problem = \"AC\" # AD AC\n",
    "TrainingPercentage = 0.7\n",
    "ValidationPercentage = 0.1\n",
    "TestingPercentage = 0.2\n",
    "\n",
    "\n",
    "\n",
    "no_runs = 5\n",
    "\n",
    "results_2_1 = []\n",
    "results_2_2 = []\n",
    "results_2_3 = []\n",
    "results_2_4 = []\n",
    "\n",
    "k = 1\n",
    "while k<=no_runs:\n",
    "    # Dividing the dataset\n",
    "    print(\"RUN \" + str(k))\n",
    "\n",
    "    if dataset == \"iris\":\n",
    "        iris = load_iris()\n",
    "        data, target = iris.data, iris.target\n",
    "\n",
    "    if dataset == \"kdd\":\n",
    "        file_name = \"data\" + separator + \"kdd_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 3\n",
    "\n",
    "\n",
    "    if dataset == \"nsl_kdd\":\n",
    "        file_name = \"data\" + separator + \"nsl_kdd_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 4\n",
    "\n",
    "    if dataset == \"unsw_nb15\":\n",
    "        file_name = \"data\" + separator + \"unsw_nb15_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 4\n",
    "\n",
    "    if dataset == \"cic_ids_2017\":\n",
    "        file_name = \"data\" + separator +  \"cic_ids_2017_subsets.pbz2\"\n",
    "        f = bz2.BZ2File(file_name, \"rb\")\n",
    "        data, target, subsets = cPickle.load(f)\n",
    "        f.close()\n",
    "        label_for_normal = 0\n",
    "\n",
    "    if problem == \"AD\" and dataset != \"iris\":\n",
    "        target[target != label_for_normal] = 1\n",
    "        target[target == label_for_normal] = 0\n",
    "\n",
    "    num_classes = np.unique(target).shape[0]\n",
    "\n",
    "\n",
    "    uniqueSubsets = np.unique(subsets)\n",
    "\n",
    "    total_number_instances = len(data)\n",
    "    indexes = range(len(data))\n",
    "    indexes = random.sample(indexes, round(TrainingPercentage * total_number_instances))\n",
    "    dataTraining = data[indexes,:]\n",
    "    targetTraining = target[indexes]\n",
    "    subsetsTraining = subsets[indexes]\n",
    "    data = np.delete(data, indexes, axis = 0)\n",
    "    target = np.delete(target, indexes, axis = 0)\n",
    "    subsets = np.delete(subsets, indexes, axis = 0)\n",
    "    indexes = range(len(data))\n",
    "    indexes = random.sample(indexes, round(ValidationPercentage * total_number_instances))\n",
    "    dataValidation = data[indexes,:]\n",
    "    targetValidation = target[indexes]\n",
    "    subsetsValidation = subsets[indexes]\n",
    "    dataTesting = np.delete(data, indexes, axis = 0)\n",
    "    targetTesting = np.delete(target, indexes, axis = 0)\n",
    "    subsetsTesting = np.delete(subsets, indexes, axis = 0)\n",
    "\n",
    "    algorithms = []\n",
    "\n",
    "    percentage = 0.7\n",
    "    if dataset == \"kdd\" and problem == \"AD\" :\n",
    "        num_trees = 65\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"kdd\" and problem == \"AC\" :\n",
    "        num_trees = 53\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "\n",
    "    if dataset == \"nsl_kdd\" and problem == \"AD\" :\n",
    "        num_trees = 65\n",
    "        criterion_input = 'gini' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"nsl_kdd\" and problem == \"AC\" :\n",
    "        num_trees = 31\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"unsw_nb15\" and problem == \"AD\" :\n",
    "        num_trees = 93\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "\n",
    "    if dataset == \"unsw_nb15\" and problem == \"AC\" :\n",
    "        num_trees = 61\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"SV\"\n",
    "\n",
    "    if dataset == \"cic_ids_2017\" and problem == \"AD\" :\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "        num_trees = 77\n",
    "\n",
    "    if dataset == \"cic_ids_2017\" and problem == \"AC\" :\n",
    "        criterion_input = 'entropy' #[\"gini\", \"entropy\"]\n",
    "        ensemble_method = \"WV\"\n",
    "        num_trees = 95\n",
    "\n",
    "    ok = 1\n",
    "\n",
    "    for i in range(len(uniqueSubsets)):\n",
    "        temp_result = \"\"\n",
    "        ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "        subsetDataTraining = dataTraining[ind_list]\n",
    "        subsetTargetTraining = targetTraining[ind_list]\n",
    "        ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "        subsetDataValidation = dataValidation[ind_list]\n",
    "        subsetTargetValidation = targetValidation[ind_list]\n",
    "        ind_list = np.where(subsetsTesting == uniqueSubsets[i])\n",
    "        subsetDataTesting = dataTesting[ind_list]\n",
    "        subsetTargetTesting = targetTesting[ind_list]\n",
    "        if subsetDataTraining.shape[0] == 0 or subsetDataValidation.shape[0]==0 or subsetDataTesting.shape[0] == 0:\n",
    "            print(\"not ok \" + uniqueSubsets[i] + \", again\")\n",
    "            ok = 0\n",
    "\n",
    "    if ok == 0:\n",
    "        continue\n",
    "\n",
    "    f = bz2.BZ2File(folderName+separator+dataset+\"_\"+problem+\"_\"+str(k)+ \"_subsets_for_Experiment3.pbz2\", \"wb\")\n",
    "    cPickle.dump((dataTraining,targetTraining,subsetsTraining,dataValidation,targetValidation,subsetsValidation,dataTesting,targetTesting,subsetsTesting),f)\n",
    "    f.close()\n",
    "\n",
    "    result = \"\"\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    print(\"         \" + str(k)  + \"   EXPERIMENT 2.1\")\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    one_run_2_1 = []\n",
    "    if division == \"subsets\":\n",
    "        result = result + \"2.1\\n\\n\\n\"\n",
    "\n",
    "        for i in range(len(uniqueSubsets)):\n",
    "            temp_result = \"\"\n",
    "            ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "            subsetDataTraining = dataTraining[ind_list]\n",
    "            subsetTargetTraining = targetTraining[ind_list]\n",
    "            ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "            subsetDataValidation = dataValidation[ind_list]\n",
    "            subsetTargetValidation = targetValidation[ind_list]\n",
    "            ind_list = np.where(subsetsTesting == uniqueSubsets[i])\n",
    "            subsetDataTesting = dataTesting[ind_list]\n",
    "            subsetTargetTesting = targetTesting[ind_list]\n",
    "\n",
    "            total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+str(uniqueSubsets[i])+\"\\n\"\n",
    "            temp_result = temp_result + \"Total number of instances: \"+str(total_number_instances_subset)+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number whole Testing Cases: \"+str(subsetDataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "            print(temp_result)\n",
    "\n",
    "            temp_result = temp_result + \"numTrees: \"+str(num_trees)+\"\\n\"\n",
    "            algorithms.append(RF.RandomForest(num_trees, criterion_input, ensemble_method, num_classes))\n",
    "            algorithms[-1].fit(subsetDataTraining, subsetTargetTraining, percentage)\n",
    "            algorithms[-1].validate(subsetDataValidation, subsetTargetValidation)\n",
    "            algorithms[-1].predict(subsetDataTesting, subsetTargetTesting)\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[-1].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[-1].statisticsRF.precision) + \"Recall: \" + str(algorithms[-1].statisticsRF.recall) + \"F1: \" + str(algorithms[-1].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_1.append(algorithms[-1].statisticsRF)\n",
    "            print(\"\\nAccuracy: \" + str(algorithms[-1].statisticsRF.accuracy)+\"\\n\")\n",
    "            result = result + temp_result\n",
    "        results_2_1.append(one_run_2_1)\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    print(\"         \" + str(k)  + \"  EXPERIMENT 2.2\")\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "\n",
    "    if division == \"subsets\":\n",
    "        result = result + \"\\n\\n\\n2.2\\n\\n\\n\"\n",
    "        one_run_2_2 = []\n",
    "        for i in range(len(uniqueSubsets)):\n",
    "            temp_result = \"\"\n",
    "\n",
    "            ind_list = np.where(subsetsTraining == uniqueSubsets[i])\n",
    "            subsetDataTraining = dataTraining[ind_list]\n",
    "            subsetTargetTraining = targetTraining[ind_list]\n",
    "            ind_list = np.where(subsetsValidation == uniqueSubsets[i])\n",
    "            subsetDataValidation = dataValidation[ind_list]\n",
    "            subsetTargetValidation = targetValidation[ind_list]\n",
    "\n",
    "            total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+str(uniqueSubsets[i])+\"\\n\"\n",
    "            temp_result = temp_result + \"Total number of instances: \"+str(total_number_instances_subset)+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result + \"Number whole Testing Cases: \"+str(dataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "\n",
    "\n",
    "            temp_result = temp_result + \"numTrees: \"+str(num_trees)+\"\\n\"\n",
    "\n",
    "            algorithms[i].predict(dataTesting, targetTesting)\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[i].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[i].statisticsRF.precision) + \"Recall: \" + str(algorithms[i].statisticsRF.recall) + \"F1: \" + str(algorithms[i].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_2.append(algorithms[i].statisticsRF)\n",
    "            print(temp_result)\n",
    "            result = result + temp_result\n",
    "        results_2_2.append(one_run_2_2)\n",
    "\n",
    "        f = open(folderName+\"\\\\\"+\"Experiment_2_2_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method, \"wb\")\n",
    "        f = bz2.BZ2File(folderName+separator+\"Experiment_2_2_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method+ \"_\" + str(k) + \".pbz2\", \"wb\")\n",
    "        cPickle.dump((algorithms),f)\n",
    "        f.close()\n",
    "        print(\"Results 2.1\")\n",
    "        print(results_2_1)\n",
    "        print(\"Results 2.2\")\n",
    "        print(results_2_2)\n",
    "\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    print(\"            EXPERIMENT 2.3\")\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "\n",
    "    if division == \"random_equal\":\n",
    "        one_run_2_3 = []\n",
    "\n",
    "        total_subsets =  len(uniqueSubsets)\n",
    "        per_subset_training = len(dataTraining)/total_subsets\n",
    "        per_subset_validation = len(dataValidation)/total_subsets\n",
    "\n",
    "        print(\"Total training: \" + str(len(dataTraining)))\n",
    "        print(\"Subsets: \" + str(total_subsets))\n",
    "        print(\"Per subset: \" + str(per_subset_training))\n",
    "\n",
    "        for i in range(total_subsets):\n",
    "            temp_result = \"\"\n",
    "\n",
    "            indexes = range(len(dataTraining))\n",
    "            indexes = random.sample(indexes, int(per_subset_training))\n",
    "\n",
    "            subsetDataTraining = dataTraining[indexes,:]\n",
    "            subsetTargetTraining = targetTraining[indexes]\n",
    "\n",
    "            dataTraining = np.delete(dataTraining, indexes, axis = 0)\n",
    "            targetTraining = np.delete(targetTraining, indexes, axis = 0)\n",
    "\n",
    "            indexes = range(len(dataValidation))\n",
    "            indexes = random.sample(indexes, int(per_subset_validation))\n",
    "\n",
    "            subsetDataValidation = dataValidation[indexes,:]\n",
    "            subsetTargetValidation = targetValidation[indexes]\n",
    "\n",
    "            dataValidation = np.delete(dataValidation, indexes, axis = 0)\n",
    "            targetValidation = np.delete(targetValidation, indexes, axis = 0)\n",
    "            # total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "            subset_name = str(i+1);\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+subset_name+\"\\n\"\n",
    "            # print(\"Total number of instances: \"+str(total_number_instances_subset))\n",
    "            temp_result = temp_result +\"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result +\"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result +\"Number Whole Testing Cases: \"+str(dataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "\n",
    "\n",
    "            temp_result = temp_result +\"numTrees: \"+str(num_trees)\n",
    "\n",
    "            algorithms.append(RF.RandomForest(num_trees, criterion_input, ensemble_method, num_classes))\n",
    "\n",
    "            algorithms[-1].fit(subsetDataTraining, subsetTargetTraining, percentage)\n",
    "            algorithms[-1].validate(subsetDataValidation, subsetTargetValidation)\n",
    "            algorithms[-1].predict(dataTesting, targetTesting)\n",
    "\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[i].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[i].statisticsRF.precision) + \"Recall: \" + str(algorithms[i].statisticsRF.recall) + \"F1: \" + str(algorithms[i].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_3.append(algorithms[i].statisticsRF)\n",
    "            print(temp_result)\n",
    "            result = result + temp_result\n",
    "        results_2_3.append(one_run_2_3)\n",
    "\n",
    "        print(\"Results 2.3\")\n",
    "        print(results_2_3)\n",
    "\n",
    "        f = bz2.BZ2File(folderName+separator+\"Experiment_2_3_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method+ \"_\" + str(k) + \".pbz2\", \"wb\")\n",
    "        cPickle.dump(algorithms,f)\n",
    "        f.close()\n",
    "\n",
    "    if division == \"random_same\":\n",
    "        one_run_2_4 = []\n",
    "        total_subsets =  len(uniqueSubsets)\n",
    "        for i in range(total_subsets):\n",
    "            temp_result = \"\"\n",
    "\n",
    "            per_subset_training = len(np.array(np.where(subsetsTraining == uniqueSubsets[i])[0]))\n",
    "            per_subset_validation =len(np.array(np.where(subsetsValidation == uniqueSubsets[i])[0]))\n",
    "\n",
    "            indexes = range(len(dataTraining))\n",
    "            indexes = random.sample(indexes,per_subset_training)\n",
    "\n",
    "            subsetDataTraining = dataTraining[indexes,:]\n",
    "            subsetTargetTraining = targetTraining[indexes]\n",
    "\n",
    "            dataTraining = np.delete(dataTraining, indexes, axis = 0)\n",
    "            targetTraining = np.delete(targetTraining, indexes, axis = 0)\n",
    "\n",
    "            indexes = range(len(dataValidation))\n",
    "            indexes = random.sample(indexes, per_subset_validation)\n",
    "\n",
    "            subsetDataValidation = dataValidation[indexes,:]\n",
    "            subsetTargetValidation = targetValidation[indexes]\n",
    "\n",
    "            dataValidation = np.delete(dataValidation, indexes, axis = 0)\n",
    "            targetValidation = np.delete(targetValidation, indexes, axis = 0)\n",
    "            # total_number_instances_subset = subsetDataTraining.shape[0] + subsetDataValidation.shape[0] + subsetDataTesting.shape[0]\n",
    "\n",
    "            subset_name = str(i+1);\n",
    "\n",
    "            temp_result = temp_result + \"\\n INFORMATION\\n\"+\"\\n\"\n",
    "            temp_result = temp_result + \"Dataset: \"+dataset+\"\\n\"\n",
    "            temp_result = temp_result + \"Subset: \"+subset_name+\"\\n\"\n",
    "            # print(\"Total number of instances: \"+str(total_number_instances_subset))\n",
    "            temp_result = temp_result +\"Number Training Cases: \"+str(subsetDataTraining.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result +\"Number Validation Cases: \"+str(subsetDataValidation.shape[0])+\"\\n\"\n",
    "            temp_result = temp_result +\"Number Whole Testing Cases: \"+str(dataTesting.shape[0])+\"\\n\"+\"\\n\"\n",
    "\n",
    "\n",
    "            temp_result = temp_result +\"numTrees: \"+str(num_trees)\n",
    "\n",
    "            algorithms.append(RF.RandomForest(num_trees, criterion_input, ensemble_method, num_classes))\n",
    "\n",
    "            algorithms[-1].fit(subsetDataTraining, subsetTargetTraining, percentage)\n",
    "            algorithms[-1].validate(subsetDataValidation, subsetTargetValidation)\n",
    "            algorithms[-1].predict(dataTesting, targetTesting)\n",
    "\n",
    "            temp_result = temp_result + \"\\nAccuracy: \" + str(algorithms[i].statisticsRF.accuracy)+ \"Precision: \" + str(algorithms[i].statisticsRF.precision) + \"Recall: \" + str(algorithms[i].statisticsRF.recall) + \"F1: \" + str(algorithms[i].statisticsRF.f1)+\"\\n\"\n",
    "            one_run_2_4.append(algorithms[i].statisticsRF)\n",
    "            print(temp_result)\n",
    "            result = result + temp_result\n",
    "        results_2_4.append(one_run_2_4)\n",
    "\n",
    "        print(\"Results 2.4\")\n",
    "        print(results_2_4)\n",
    "\n",
    "        f = open(folderName+\"\\\\\"+\"Experiment_2_1_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method, \"wb\")\n",
    "        f = bz2.BZ2File(folderName+separator+\"Experiment_2_1_RF_\"+dataset+\"_\"+problem+\"_\"+criterion_input+\"_\"+ensemble_method+\".pbz2\", \"wb\")\n",
    "        cPickle.dump((algorithms),f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    f1 = open(folderName+separator+\"output_\"+dataset+\"_\"+problem+\".txt\", \"w\")\n",
    "    f1.write(result)\n",
    "    f1.close()\n",
    "\n",
    "    k = k + 1\n",
    "\n",
    "if division == \"subsets\":\n",
    "    avg_2_1 = []\n",
    "    avg_2_2 = []\n",
    "\n",
    "    prec_2_1 = []\n",
    "    prec_2_2 = []\n",
    "\n",
    "    recall_2_1 = []\n",
    "    recall_2_2 = []\n",
    "\n",
    "\n",
    "    f1_2_1 = []\n",
    "    f1_2_2 = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum2a = 0\n",
    "        sum1p = 0\n",
    "        sum2p = 0\n",
    "        sum1r = 0\n",
    "        sum2r = 0\n",
    "        sum1f = 0\n",
    "        sum2f = 0\n",
    "        for z in range(len(results_2_1)):\n",
    "           sum1a = sum1a + results_2_1[z][k].accuracy\n",
    "           sum2a = sum2a + results_2_2[z][k].accuracy\n",
    "           sum1p = sum1p + results_2_1[z][k].precision\n",
    "           sum2p = sum2p + results_2_2[z][k].precision\n",
    "           sum1r = sum1r + results_2_1[z][k].recall\n",
    "           sum2r = sum2r + results_2_2[z][k].recall\n",
    "           sum1f = sum1f + results_2_1[z][k].f1\n",
    "           sum2f = sum2f + results_2_2[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        avg_temp2 = sum2a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        prec_temp2 = sum2p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        r_temp2 = sum2r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        f1_temp2 = sum2f/no_runs\n",
    "        avg_2_1.append(avg_temp1)\n",
    "        avg_2_2.append(avg_temp2)\n",
    "        prec_2_1.append(prec_temp1)\n",
    "        prec_2_2.append(prec_temp2)\n",
    "        recall_2_1.append(r_temp1)\n",
    "        recall_2_2.append(r_temp2)\n",
    "        f1_2_1.append(f1_temp1)\n",
    "        f1_2_2.append(f1_temp2)\n",
    "\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_1.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/accuracy\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/precision\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/recall\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_1)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_1[k][j].accuracy)\n",
    "            oneRow.append(results_2_1[k][j].precision*100)\n",
    "            oneRow.append(results_2_1[k][j].recall*100)\n",
    "            oneRow.append(results_2_1[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_1[j])\n",
    "        lastRow.append(prec_2_1[j]*100)\n",
    "        lastRow.append(recall_2_1[j]*100)\n",
    "        lastRow.append(f1_2_1[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_2.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(firstRow)\n",
    "    for k in range(len(results_2_2)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_2[k][j].accuracy)\n",
    "            oneRow.append(results_2_2[k][j].precision*100)\n",
    "            oneRow.append(results_2_2[k][j].recall*100)\n",
    "            oneRow.append(results_2_2[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_2[j])\n",
    "        lastRow.append(prec_2_2[j]*100)\n",
    "        lastRow.append(recall_2_2[j]*100)\n",
    "        lastRow.append(f1_2_2[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if division == \"random_equal\":\n",
    "    avg_2_3 = []\n",
    "    prec_2_3 = []\n",
    "    recall_2_3 = []\n",
    "    f1_2_3 = []\n",
    "\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum1p = 0\n",
    "        sum1r = 0\n",
    "        sum1f = 0\n",
    "        for z in range(len(results_2_3)):\n",
    "            sum1a = sum1a + results_2_3[z][k].accuracy\n",
    "            sum1p = sum1p + results_2_3[z][k].precision\n",
    "            sum1r = sum1r + results_2_3[z][k].recall\n",
    "            sum1f = sum1f + results_2_3[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        avg_2_3.append(avg_temp1)\n",
    "        prec_2_3.append(prec_temp1)\n",
    "        recall_2_3.append(r_temp1)\n",
    "        f1_2_3.append(f1_temp1)\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_3.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/accuracy\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/precision\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/recall\")\n",
    "        firstRow.append(str(uniqueSubsets[k]) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_3)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_3[k][j].accuracy)\n",
    "            oneRow.append(results_2_3[k][j].precision*100)\n",
    "            oneRow.append(results_2_3[k][j].recall*100)\n",
    "            oneRow.append(results_2_3[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_3[j])\n",
    "        lastRow.append(prec_2_3[j]*100)\n",
    "        lastRow.append(recall_2_3[j]*100)\n",
    "        lastRow.append(f1_2_3[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "if division == \"random_same\":\n",
    "    avg_2_4 = []\n",
    "    prec_2_4 = []\n",
    "    recall_2_4 = []\n",
    "    f1_2_4 = []\n",
    "\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        sum1a = 0\n",
    "        sum1p = 0\n",
    "        sum1r = 0\n",
    "        sum1f = 0\n",
    "        for z in range(len(results_2_4)):\n",
    "            sum1a = sum1a + results_2_4[z][k].accuracy\n",
    "            sum1p = sum1p + results_2_4[z][k].precision\n",
    "            sum1r = sum1r + results_2_4[z][k].recall\n",
    "            sum1f = sum1f + results_2_4[z][k].f1\n",
    "        avg_temp1 = sum1a/no_runs\n",
    "        prec_temp1 = sum1p/no_runs\n",
    "        r_temp1 = sum1r/no_runs\n",
    "        f1_temp1 = sum1f/no_runs\n",
    "        avg_2_4.append(avg_temp1)\n",
    "        prec_2_4.append(prec_temp1)\n",
    "        recall_2_4.append(r_temp1)\n",
    "        f1_2_4.append(f1_temp1)\n",
    "\n",
    "    f = open(folderName+separator+dataset+\"_\"+problem+\"_\"\"results_2_4.csv\", 'w')\n",
    "    writer = csv.writer(f)\n",
    "    firstRow  = []\n",
    "    for k in range(len(uniqueSubsets)):\n",
    "        firstRow.append(str(k+1) + \"/accuracy\")\n",
    "        firstRow.append(str(k+1) + \"/precision\")\n",
    "        firstRow.append(str(k+1) + \"/recall\")\n",
    "        firstRow.append(str(k+1) + \"/f1\")\n",
    "    writer.writerow(firstRow)\n",
    "\n",
    "    for k in range(len(results_2_4)):\n",
    "        oneRow = []\n",
    "        for j in range(len(uniqueSubsets)):\n",
    "            oneRow.append(results_2_4[k][j].accuracy)\n",
    "            oneRow.append(results_2_4[k][j].precision*100)\n",
    "            oneRow.append(results_2_4[k][j].recall*100)\n",
    "            oneRow.append(results_2_4[k][j].f1*100)\n",
    "        writer.writerow(oneRow)\n",
    "    lastRow = []\n",
    "    for j in range(len(uniqueSubsets)):\n",
    "        lastRow.append(avg_2_4[j])\n",
    "        lastRow.append(prec_2_4[j]*100)\n",
    "        lastRow.append(recall_2_4[j]*100)\n",
    "        lastRow.append(f1_2_4[j]*100)\n",
    "    writer.writerow(lastRow)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}