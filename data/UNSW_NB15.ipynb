{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf9057ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 82332\n",
      "No. of rows without some classes: 80650\n",
      "Total number of features + target:  179\n",
      "Number of instances/attacks for used services: \n",
      "-  ->  45516 , attacks:  18141\n",
      "http  ->  8244 , attacks:  4231\n",
      "ftp  ->  1550 , attacks:  792\n",
      "ftp-data  ->  1396 , attacks:  447\n",
      "smtp  ->  1851 , attacks:  1216\n",
      "dns  ->  21367 , attacks:  18299\n",
      "Number of used service:  6\n",
      "Number of instances:  80650\n",
      "Final features:  177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "\n",
    "path = 'folder_with_raw_data'\n",
    "# 0 - whole dataset, 1 - dataset for subsets, 2 - dataset for subsets with others\n",
    "create_subset  = 0\n",
    "\n",
    "df = pd.read_csv(path + 'UNSW_NB15_training-set.csv')\n",
    "\n",
    "\n",
    "print(\"Total rows:\", df.shape[0])\n",
    "\n",
    "# remove id and label from data frame\n",
    "# 44 features\n",
    "df = df.drop(['id','label',],axis= 1)\n",
    "\n",
    "# one hot encoding for protocol -> +131 columns\n",
    "# print(len(df['proto'].unique()))\n",
    "# print((df['proto'].unique()))\n",
    "one_hot_proto = pd.get_dummies(df['proto'])\n",
    "df = df.drop('proto',axis = 1)\n",
    "df = df.join(one_hot_proto)\n",
    "\n",
    "if create_subset ==0:\n",
    "# one hot encoding for service -> +13 columns\n",
    "# print(len(df['service'].unique()))\n",
    "    one_hot_service = pd.get_dummies(df['service'])\n",
    "    df = df.drop('service',axis = 1)\n",
    "    df = df.join(one_hot_service)\n",
    "\n",
    "# one hot encoding for state -> +7 columns\n",
    "# print(len(df['state'].unique()))\n",
    "one_hot_state = pd.get_dummies(df['state'])\n",
    "df = df.drop('state',axis = 1)\n",
    "df = df.join(one_hot_state)\n",
    "\n",
    "# classes to remove\n",
    "# Analysis, Backdoors, Shell-code, Worms\n",
    "# print(df['attack_cat'].unique())\n",
    "\n",
    "options = ['Analysis', 'Backdoor', 'Shellcode','Worms']\n",
    "df = df[~df['attack_cat'].isin(options)]\n",
    "\n",
    "print(\"No. of rows without some classes:\", df.shape[0])\n",
    "print(\"Total number of features + target: \", df.shape[1])\n",
    "\n",
    "# encoding for output - attack_cat\n",
    "le = LabelEncoder()\n",
    "le.fit(df['attack_cat'].unique())\n",
    "df['attack_cat'] = le.transform(df['attack_cat'])\n",
    "\n",
    "if create_subset  == 1 or create_subset  == 2:\n",
    "    array = df['service'].unique()\n",
    "    n = len(array)\n",
    "\n",
    "    print(\"Number of instances/attacks for used services: \" )\n",
    "\n",
    "    # remove services with less then 50 instances of both classes\n",
    "\n",
    "    used_services = 0\n",
    "    remove_services = [];\n",
    "    for i in range(n):\n",
    "        subset = df[df['service'] == array[i]]\n",
    "        rows = subset.shape[0]\n",
    "        attack_rows = subset[subset['attack_cat'] != le.transform(['Normal'])[0]].shape[0]\n",
    "        normal_rows = subset[subset['attack_cat'] == le.transform(['Normal'])[0]].shape[0]\n",
    "        if normal_rows>50 and attack_rows>50:\n",
    "            print(array[i], \" -> \", subset.shape[0] , \", attacks: \", attack_rows)\n",
    "            used_services = used_services+1\n",
    "        else:\n",
    "            remove_services.append(array[i])\n",
    "\n",
    "    print(\"Number of used service: \", used_services )\n",
    "    print(\"Number of instances: \", df.shape[0] )\n",
    "\n",
    "if create_subset  == 0:\n",
    "    data = df\n",
    "    # target\n",
    "    target = np.array(data['attack_cat'])\n",
    "\n",
    "    # data\n",
    "    data = data.drop(['attack_cat'],axis= 1)\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    f = bz2.BZ2File(\"unsw_nb15.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target),f)\n",
    "    f.close()\n",
    "\n",
    "if create_subset  == 1:\n",
    "    data = df\n",
    "    data = data[~data['service'].isin(remove_services)]\n",
    "\n",
    "    # target\n",
    "    target = np.array(data['attack_cat'])\n",
    "\n",
    "    # subsets\n",
    "    subsets = np.array(data['service'])\n",
    "\n",
    "    # data\n",
    "    dataS = data.drop(['service'],axis= 1)\n",
    "    dataS = data.drop(['attack_cat'],axis= 1)\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    print(\"Final features: \", dataS.shape[1])\n",
    "\n",
    "    # f = open(\"unsw_nb15_subsets\", \"wb\")\n",
    "    f = bz2.BZ2File(\"unsw_nb15_subsets.pbz2\", \"wb\")\n",
    "    cPickle.dump((dataS,target,subsets),f)\n",
    "    f.close()\n",
    "\n",
    "if create_subset  == 2:\n",
    "    data = df\n",
    "\n",
    "    data['service'].replace(dict.fromkeys(remove_services, 'others'), inplace=True )\n",
    "\n",
    "    # target\n",
    "    target = np.array(data['attack_cat'])\n",
    "\n",
    "    # subsets\n",
    "    subsets = np.array(data['service'])\n",
    "\n",
    "    # data\n",
    "    data = data.drop(['attack_cat'],axis= 1)\n",
    "    data = data.drop(['service'],axis= 1)\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    # f = open(\"unsw_nb15_subsets\", \"wb\")\n",
    "    f = bz2.BZ2File(\"unsw_nb15_subsets_new.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target,subsets),f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}