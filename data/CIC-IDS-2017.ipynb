{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows:  2012223\n",
      "No. of rows without some classes: 2011539\n",
      "Total number of features + target:  77\n",
      "Number of rows for each destination port: \n",
      "21  ->  11781 , attacks:  8181\n",
      "22  ->  13498 , attacks:  6140\n",
      "53  ->  643986 , attacks:  159\n",
      "80  ->  541594 , attacks:  382566\n",
      "88  ->  3920 , attacks:  159\n",
      "135  ->  749 , attacks:  160\n",
      "139  ->  1921 , attacks:  197\n",
      "389  ->  4477 , attacks:  159\n",
      "443  ->  312986 , attacks:  240\n",
      "445  ->  1195 , attacks:  179\n",
      "465  ->  2656 , attacks:  160\n",
      "1124  ->  259 , attacks:  160\n",
      "3268  ->  1903 , attacks:  160\n",
      "8080  ->  2610 , attacks:  1421\n",
      "Final features:  75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "\n",
    "path = 'folder_with_raw_data';\n",
    "\n",
    "files = ['Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "         'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "         'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "         'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "         'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "         'Wednesday-workingHours.pcap_ISCX.csv']\n",
    "\n",
    "# 0 - whole dataset, 1 - dataset for subsets, 2 - dataset for subsets with others\n",
    "create_subset  = 2\n",
    "\n",
    "n = len(files)\n",
    "finalDF = pd.read_csv(path + files[0])\n",
    "\n",
    "for i in range(1,n):\n",
    "    df = pd.read_csv(path + files[i])\n",
    "    finalDF = pd.concat([finalDF, df])\n",
    "\n",
    "print(\"Total rows: \" , finalDF.shape[0])\n",
    "\n",
    "# remove Flow Bytes/s,Flow Packets/s from data frame\n",
    "finalDF = finalDF.drop(['Flow Bytes/s', ' Flow Packets/s'],axis= 1)\n",
    "\n",
    "# print(\"Total columns: \" , finalDF.shape[1])\n",
    "\n",
    "#classes to remove\n",
    "\n",
    "array = finalDF[' Label'].unique()\n",
    "n = len(array)\n",
    "classes_to_remove = []\n",
    "\n",
    "for i in range(n):\n",
    "    subset = finalDF[finalDF[' Label'] == array[i]]\n",
    "    rows = subset.shape[0]\n",
    "    if rows<=800:\n",
    "        classes_to_remove.append(array[i])\n",
    "\n",
    "# print(classes_to_remove)\n",
    "# remove classes\n",
    "finalDF = finalDF[~finalDF[' Label'].isin(classes_to_remove)]\n",
    "print(\"No. of rows without some classes:\", finalDF.shape[0])\n",
    "print(\"Total number of features + target: \", finalDF.shape[1])\n",
    "\n",
    "# encoding for output - Label\n",
    "le = LabelEncoder()\n",
    "le.fit(finalDF[' Label'].unique())\n",
    "finalDF[' Label'] = le.transform(finalDF[' Label'])\n",
    "\n",
    "\n",
    "if create_subset==1 or create_subset ==2:\n",
    "    array = finalDF[' Destination Port'].unique()\n",
    "    n = len(array)\n",
    "    array.sort()\n",
    "\n",
    "    print(\"Number of rows for each destination port: \")\n",
    "\n",
    "    count_ports = 0\n",
    "    count_rows = 0\n",
    "    count_attack_rows = 0\n",
    "    remove_ports = [];\n",
    "\n",
    "    for i in range(n):\n",
    "        current_df = finalDF[finalDF[' Destination Port'] == array[i]]\n",
    "        rows = current_df.shape[0]\n",
    "        attack_rows = current_df[current_df[' Label'] != le.transform(['BENIGN'])[0]].shape[0]\n",
    "        normal_rows = current_df[current_df[' Label'] == le.transform(['BENIGN'])[0]].shape[0]\n",
    "        if normal_rows>50 and attack_rows>50:\n",
    "            print(array[i], \" -> \", rows, \", attacks: \", attack_rows)\n",
    "            count_ports = count_ports + 1\n",
    "            count_rows = count_rows + rows\n",
    "            count_attack_rows = count_attack_rows + attack_rows\n",
    "        else:\n",
    "            remove_ports.append(array[i])\n",
    "\n",
    "    # print(\"Total number of used ports: \", count_ports)\n",
    "    # percentage = '{0:.3g}'.format(count_rows/finalDF.shape[0]*100)\n",
    "    # print(\"Total rows covered: \", count_rows, \"(\", percentage,\"%)\")\n",
    "    # percentage_attacks = '{0:.3g}'.format(count_attack_rows/count_rows*100)\n",
    "    # print(\"Total attacks: \", count_attack_rows, \"(\", percentage_attacks,\"%)\")\n",
    "\n",
    "    # print(\"Number of instances: \", finalDF.shape[0] )\n",
    "\n",
    "data = finalDF\n",
    "\n",
    "\n",
    "if create_subset == 0:\n",
    "    # target\n",
    "    target = np.array(data[' Label'])\n",
    "\n",
    "    # data\n",
    "    data = data.drop([' Label'],axis= 1)\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "    f = bz2.BZ2File(\"cic_ids_2017.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target),f)\n",
    "    f.close()\n",
    "\n",
    "if create_subset == 1:\n",
    "    data = data[~data[' Destination Port'].isin(remove_ports)]\n",
    "\n",
    "    # target\n",
    "    target = np.array(data[' Label'])\n",
    "\n",
    "    # subsets\n",
    "    subsets = np.array(data[' Destination Port'])\n",
    "\n",
    "    # data\n",
    "    data = data.drop([' Label'],axis= 1)\n",
    "    data = data.drop([' Destination Port'],axis= 1)\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    f = bz2.BZ2File(\"cic_ids_2017_subsets.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target,subsets),f)\n",
    "    f.close()\n",
    "\n",
    "if create_subset == 2:\n",
    "    data[' Destination Port'].replace(dict.fromkeys(remove_ports, -1), inplace=True )\n",
    "\n",
    "    # target\n",
    "    target = np.array(data[' Label'])\n",
    "\n",
    "    # subsets\n",
    "    subsets = np.array(data[' Destination Port'])\n",
    "\n",
    "    # data\n",
    "    data = data.drop([' Label'],axis= 1)\n",
    "    data = data.drop([' Destination Port'],axis= 1)\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    f = bz2.BZ2File(\"cic_ids_2017_subsets_new.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target,subsets),f)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}