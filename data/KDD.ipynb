{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9057ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 494021\n",
      "Total columns: 42\n",
      "No. of rows without some classes: 493347\n",
      "Total number of features + target:  117\n",
      "Number of rows for each protocol: ( 3 protocol )\n",
      "icmp  ->  283235 , attacks:  281947\n",
      "tcp  ->  189786 , attacks:  112973\n",
      "udp  ->  20326 , attacks:  1149\n",
      "Final features:  115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "\n",
    "\n",
    "path = 'folder_with_raw_data';\n",
    "# 0 - whole dataset, 1 - dataset for subsets\n",
    "create_subset  = 1\n",
    "\n",
    "\n",
    "df = pd.read_csv(path + 'kdd',header=None)\n",
    "\n",
    "print(\"Total rows:\", df.shape[0])\n",
    "print(\"Total columns:\", df.shape[1])\n",
    "\n",
    "if create_subset==0:\n",
    "    # one hot encoding for protocol -> +3 columns\n",
    "    # print(df[1].unique())\n",
    "    # print(len(df[1].unique()))\n",
    "    one_hot_proto = pd.get_dummies(df[1])\n",
    "    df = df.drop(1,axis = 1)\n",
    "    df = df.join(one_hot_proto)\n",
    "\n",
    "# one hot encoding for service -> +66 columns\n",
    "# print(len(df[2].unique()))\n",
    "one_hot_service = pd.get_dummies(df[2])\n",
    "df = df.drop(2,axis = 1)\n",
    "df = df.join(one_hot_service)\n",
    "# print(\"Total columns:\", df.shape[1])\n",
    "\n",
    "# one hot encoding for flag -> +11 columns\n",
    "# print(df[3].unique())\n",
    "# print(len(df[3].unique()))\n",
    "one_hot_flag = pd.get_dummies(df[3])\n",
    "df = df.drop(3,axis = 1)\n",
    "df = df.join(one_hot_flag)\n",
    "\n",
    "#classes to remove\n",
    "\n",
    "array = df[41].unique()\n",
    "n = len(array)\n",
    "classes_to_remove = []\n",
    "\n",
    "for i in range(n):\n",
    "    subset = df[df[41] == array[i]]\n",
    "    rows = subset.shape[0]\n",
    "    if rows<=800:\n",
    "        classes_to_remove.append(array[i])\n",
    "\n",
    "# print(classes_to_remove)\n",
    "# remove classes\n",
    "df = df[~df[41].isin(classes_to_remove)]\n",
    "\n",
    "print(\"No. of rows without some classes:\", df.shape[0])\n",
    "print(\"Total number of features + target: \", df.shape[1])\n",
    "\n",
    "# print(df)\n",
    "# encoding for output - attack_cat\n",
    "# print(df[41].unique())\n",
    "le = LabelEncoder()\n",
    "le.fit(df[41].unique())\n",
    "df[41] = le.transform(df[41])\n",
    "\n",
    "if create_subset==1:\n",
    "    array = df[1].unique()\n",
    "    array.sort()\n",
    "    n = len(array)\n",
    "\n",
    "    print(\"Number of rows for each protocol: (\", n , \"protocol )\")\n",
    "\n",
    "    for i in range(n):\n",
    "        subset = df[df[1] == array[i]]\n",
    "        rows = subset.shape[0]\n",
    "        attack_rows = subset[subset[41] != le.transform(['normal.'])[0]].shape[0]\n",
    "        print(array[i], \" -> \", rows , \", attacks: \", attack_rows)\n",
    "\n",
    "data = df\n",
    "\n",
    "if create_subset == 0:\n",
    "    # target\n",
    "    target = np.array(data[41])\n",
    "\n",
    "    # data\n",
    "    data = data.drop([41],axis= 1)\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    f = bz2.BZ2File(\"kdd.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target),f)\n",
    "    f.close()\n",
    "\n",
    "if create_subset == 1:\n",
    "    # target\n",
    "    target = np.array(data[41])\n",
    "\n",
    "    # subsets\n",
    "    subsets = np.array(data[1])\n",
    "\n",
    "    # data\n",
    "    data = data.drop([41],axis= 1)\n",
    "    data = data.drop([1],axis= 1)\n",
    "    scaler= MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print(\"Final features: \", data.shape[1])\n",
    "\n",
    "    f = bz2.BZ2File(\"kdd_subsets.pbz2\", \"wb\")\n",
    "    cPickle.dump((data,target,subsets),f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}